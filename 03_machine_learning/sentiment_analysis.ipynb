{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice - Machine Learning pour l'analysis de sentiment\n",
    "\n",
    "Dans ce notebook, nous allons entraîner et évaluer un classifieur afin de prédire le sentiment de critiques de films sur la plateforme iMDb. C'est un cas d'école classique permettant d'aborder les thématique de la _classification binaire_ et du _traitement automatique des langues_ (_NLP_) de façon ludique.\n",
    "\n",
    "Jeu de données :\n",
    "- Source : https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "- CSV : https://github.com/Ankit152/IMDB-sentiment-analysis/raw/master/IMDB-Dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation du jeu de données\n",
    "\n",
    "Préparons notre jeu de données :\n",
    "\n",
    "1. Extraction\n",
    "2. Séparation d'un jeu d'entraînement et d'un jeu de test\n",
    "3. Analyse rapide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://github.com/Ankit152/IMDB-sentiment-analysis/raw/master/IMDB-Dataset.csv\"\n",
    "dataset = pandas.read_csv(dataset_url)\n",
    "train_dataset, test_dataset = train_test_split(dataset, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction de caractéristiques\n",
    "\n",
    "Les algorithmes de machine learning ne fonctionnent qu'avec des valeurs numériques. Or lorsque notre problème considéré relève du NLP, nous n'avons à notre disposition uniquement des chaînes de caractères. Afin de pouvoir extraire des _caractéristiques_ (_features_) numériques, voici la marche à suivre :\n",
    "\n",
    "1. _Tokenisation_ : transformer les phrases en _tokens_ / _symboles_ (par exemple en découpant par mots)\n",
    "2. _Vectorisation_ : transformer les _tokens_ en valeurs numériques (par exemple avec un _bag-of-words_ pour compter la fréquence de chaque _token_)\n",
    "\n",
    "La bibliothèque `scikit-learn` fournit le vectoriseur `CountVectorizer` permettant de tokeniser puis d'appliquer une vectorisation de type _bag-of-words_ (compte la fréquence des mots et ne garde que les N plus fréquents) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer(analyzer=\"word\", max_features=100)\n",
    "bow.fit(train_dataset[\"review\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut observer le dictionnaire construit par le vectoriseur, avec pour chaque token identifié la fréquence associée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow.vocabulary_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquons la transformation à notre jeu de données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = bow.transform(train_dataset[\"review\"]).toarray()\n",
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement d'un modèle\n",
    "\n",
    "Notre jeu de données d'entrainement est prêt, nous pouvons passer à l'entrainement d'un modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_dataset[\"sentiment\"]\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation d'un modèle\n",
    "\n",
    "Une fois l'entraînement d'un modèle effectué, il convient d'évaluer ses performance. Notre problème est de type classification binaire, nous pouvons utiliser les outils d'évaluation suivants (liste non-exhaustive) :\n",
    "- Visualisation : matrice de confusion\n",
    "- Métriques : justesse (_accuracy_), f1-score, précision, rappel (_recall_)\n",
    "\n",
    "Commençons par préparer le jeu de test **avec strictement les même traitements que le jeu d'entraînement** puis effectuer les prédictions sur le jeu de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = bow.transform(test_dataset[\"review\"])\n",
    "y_test = test_dataset[\"sentiment\"]\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons la matrice de confusion du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=lr.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=lr.classes_)\n",
    "_ = disp.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous pouvons décortiquer la matrice de confusion avec les métriques de classification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effectuer des prédictions\n",
    "\n",
    "Nous pouvons utiliser le modèle entraîné pour effectuer des prédictions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"Had a great time\"\n",
    "processed_review = bow.transform([review])\n",
    "lr.predict(processed_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"I hate this movie\"\n",
    "processed_review = bow.transform([review])\n",
    "lr.predict(processed_review)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons également observer les limites du modèle actuel :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"I love this movie\"\n",
    "processed_review = bow.transform([review])\n",
    "lr.predict(processed_review)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un petit programme interactif permettant de générer des prédictions de sentiments dynamiques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = input(\"Review: \")\n",
    "processed_review = bow.transform([review])\n",
    "predictions = lr.predict(processed_review)\n",
    "print(predictions[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "Le modèle actuel fonctionne mais avec une performance modérée : il est meilleur qu'un aléatoire mais il peut facilement se tromper dans ses prédictions :\n",
    "- D'après-vous, le modèle est-il en _sous-apprentissage_ (_underfitting_) ou _sur-apprentissage_ (_overfitting_) ?\n",
    "- Pourquoi ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin\n",
    "\n",
    "Si vous souhaitez aller plus loin, voici des pistes d'amélioration :\n",
    "\n",
    "- (facile) Augmenter la taille du dictionnaire du vectoriseur _bag-of-words_\n",
    "- (facile) Changer le vectoriseur par un TF-IDF\n",
    "- (intermédiaire) Changer le modèle par un SVM / un arbre de décision / une forêt aléatoire et comparer les résultats\n",
    "- (intermédiaire) Analyser et nettoyer le jeu de données source afin de ne garder uniquement les termes pertinents et ne pas fausser les modèles\n",
    "- (avancé) Effectuer une recherche d'hyper-paramètres afin d'optimiser au mieux un modèle\n",
    "- (avancé) Refactorer le code en utilisant la notion de _pipeline_ afin de ne pas avoir à ré-effectuer les traitement pour chaque jeu de données"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conception-architectures-ia-wEbGGQLt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
